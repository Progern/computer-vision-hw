{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hough Space line detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook presents implementation of Hough Space calculator alongside with helper function that returns **n most prominent lines** that have got most of the votes in accumulator.\n",
    "\n",
    "Also there are some helper methods for edge detection, pixel restoration, etc.\n",
    "\n",
    "Some inspiration was taken from open sources, rewritten and refactored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.insert(0, '../helpers/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several Python scripts in the *../helpers/* folder. For instance *feature_detection_helper.py* containts a lot of useful functions for pre-processing the image before transforming Hough space.\n",
    "\n",
    "You can get more sense and the documentation of the functions if you will open *feature_detection_helper.py*\n",
    "\n",
    "Other useful script is *hough_transformer.py* which contains all the necessary functions for transforming image into hough space, creating the Hough Accumulator and etc.\n",
    "\n",
    "You can get more sense and the documentation of the functions if you will open *hough_transformer.py*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Python script with usable pre-processing functions\n",
    "from feature_detection_helper import * \n",
    "\n",
    "# Helper Python script with functions to transform image into Hough Space and visualize the intersections\n",
    "\n",
    "from hough_transformer import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image_name = 'marker_cut_rgb_512.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = load_data(sample_image_name)\n",
    "sample_image_arr = np.array(sample_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TL;DR One method to solve all your problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't want to go through the notebook and just get the indicies of n-most prominent lines please feel free to use the method below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Gaussian kernel of size 3 x 3...\n",
      "Calculating gradients of the image...\n",
      "Applying Double Threshold algorithm...\n",
      "Applying Hysteresys algorithm\n",
      "Calculating the Hough Space accumulator...\n"
     ]
    }
   ],
   "source": [
    "n_lines, accumulator = hough_space_n_lines(sample_image, 3, smooth = True, double_thr_lower = 0.25, double_thr_upper = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in n_lines:\n",
    "    print(line[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2image = cv2.imread(sample_image_name, 0)\n",
    "\n",
    "plot_lines(cv2image, n_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hough space math background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A line in Cartesian form could be expressed in the equation:\n",
    "\n",
    "*y = mx + b*\n",
    "\n",
    "where: \n",
    "\n",
    "m = gradient or slope of the line (rise/run)   \n",
    "b = y-intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Example of two points with various intersections](hough_mb_parameter_space.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have two example points, for each point we can set different values of *m* and therefore obtain different intersections, and we can compute corresponding *b* values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All points on a line in image space intersect at a common point in parameter space. This common point *(m, b)* represents the line in image space.\n",
    "Unfortunately, the slope, *m*, is undefined when the line is vertical (division by 0!).\n",
    "To overcome this, we use another parameter space, the hough space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polar coordinate system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A line in Polar coordinate system could be expressed in the equation:\n",
    "\n",
    "*ρ = x cos θ + y sin θ*\n",
    "\n",
    "where:\n",
    "\n",
    "*ρ (rho)* = distance from origin to the line. [-max_dist to max_dist].\n",
    "          max_dist is the diagonal length of the image.  \n",
    "*θ* = angle from origin to the line. [-90° to 90°]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Corner or edge detection**. We can use **Canny, Sobel or Adaptive Thresholding algorithm**. The result of this step is binary or grey image with zeros indicating non-edges and ones indicating edges. The result is now interpreted as our input image\n",
    "\n",
    "2. **Rho range and Theta range creation.** ρ ranges from *-max_dist* to *+max_dist* where *max_dist* is the diagonal length of the input image (the number of diagonal entries in image matrix). θ ranges from *-90∘ to 90∘*. \n",
    "\n",
    "3. **Hough accumulator of θ vs ρ**. Is a 2D array with the number of rows equal to the number of ρ values and the number of columns equal to number of θ values.\n",
    "\n",
    "4. **Accumulator voting**. For each of the edge points and for each of θ we find the nearest corresponding ρ value and increment it index in the accumulator. Each element in our accumulator matrix tells how many pixels contributed votes for line candidate with tuple of parameters (ρ, θ)\n",
    "\n",
    "5. **Peak search**. Maximum values in the accumulator matrix indicate parameters of most probable lines in the image. Peaks could be found by applying some threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution is a simple mathematical operation which is fundamental to many common image processing operators. Convolution provides a way of multiplying together two arrays of numbers, generally of different sizes, but of the same dimensionality, to produce a third array of numbers of the same dimensionality. \n",
    "\n",
    "This can be used in image processing to implement operators whose output pixel values are simple linear combinations of certain input pixel values.\n",
    "\n",
    "The implementation is based on cpython implementation and the main inspiration/logic flow was taken from there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canny Edge Detector (CED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The Canny edge detector is an edge detection operator that uses a multi-stage algorithm to detect a wide range of edges in images. It was developed by John F. Canny in 1986. Canny also produced a computational theory of edge detection explaining why the technique works (C)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general algorithm goes in five steps:\n",
    "\n",
    "- Noise reduction\n",
    "- Image gradient calculation\n",
    "- Non-maximum suppression (*optional*)\n",
    "- Double threshold (*optional*)\n",
    "- Edge tracking\n",
    "\n",
    "\n",
    "The algorithm is based on grayscale images, so the input image should be grayscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this algorithm is based on gradient calculation it is very sensitive to image noise and the **noise reduction** stage is crucial.\n",
    "The easiest approach is to add Gaussian blur to the image to smooth it. We need to select the kernel size of the Gaussian Filter, which will set the amount of blur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Gaussian Kernel formula](gaussian_kernel_formula.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient calculation detects the edge intensity and direction by calculating the gradient of the whole image using edge detection operators.\n",
    "\n",
    "*Edges correspond to a change of pixels’ intensity. To detect it, the easiest way is to apply filters that highlight this intensity change in both directions: horizontal (x) and vertical (y)*\n",
    "\n",
    "After image smoothing phase the *Ix* and *Iy* are calculated. It could be implemented with Sobel Kernels *Kx* and *Ky*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sobel Filters](sobel_filters.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Magnitude](magnitude.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-maximum suppression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach is used to have thin edges in our images. Non-thin edges could be encountered due to various reasons - one of them is blur. The princimple is quite simple: the algorithm goes through all the points on the gradient intensity matrix and finds the pixels with maximum value in the edge directions.\n",
    "\n",
    "The purpose of the algorithm is to check if the pixels on the same direction are more or less intense than the ones being processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm flow:\n",
    "\n",
    "- Create zeros matrix of the same size as the original gradient matrix\n",
    "- Identify the edge direction based on the angle value from the matrix of angles\n",
    "- Check if the pixels in the same direction of the current processed pixel have higher intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main idea of double threshold is to identify three types of pixels: strong, weak and non-relevant. \n",
    "\n",
    "- **Strong pixels** - have very high intensity, compared to others, and will contributed to edge detection.\n",
    "- **Weak pixels** - are something in mediocre of strong and non-relevant pixels. \n",
    "- **Non-relevant** - have very low intensity and therefore won't contribute to edge detection\n",
    "\n",
    "\n",
    "So what is the idea of **double** threshold? We set two hyperparameters - **high threshold** and **low threshold**. \n",
    "\n",
    "- Pixels, that have intensity higher than high threshold are considered **strong**\n",
    "- Pixels, that have intensity lower than low threshold are considered **non-relevant**\n",
    "- All other pixels are considered **weak**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hysteresis edge tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final improvement step called the **Hysteresis** is used to transform weak pixels into strong ones if there are at least one strong pixel near the current processed weak one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Hysteresis](hysteresis.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original image\n",
    "\n",
    "imgplot = plt.imshow(sample_image_arr, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth the sample image\n",
    "\n",
    "smoothed_image = convolve_kernel(sample_image_arr, gaussian_kernel(3))\n",
    "imgplot = plt.imshow(smoothed_image, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the edges of our marker become more smooth and the edges of the the screws become smoother as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the gradients and apply non-max suppression\n",
    "\n",
    "grad_matrix, theta_matrix = sobel_filters(smoothed_image)\n",
    "imgplot = plt.imshow(grad_matrix, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-max suppression doesn't give us a lot of improvement so we therefore won't use it for this image, but it could be used for any other image and is implemented correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_max_image = non_max_suppression(grad_matrix, theta_matrix)\n",
    "imgplot = plt.imshow(non_max_image, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After non-max suppression and Sobel gradients the image became very low-saturated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply double thresholding\n",
    "\n",
    "threshold_image, weak_pixels, strong_pixels = double_threshold(grad_matrix, 0.25, 0.35)\n",
    "\n",
    "imgplot = plt.imshow(threshold_image, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double thresholding helped us to detect strong and weak pixels on the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply hysteresys search\n",
    "\n",
    "hysteresys_img = hysteresis(threshold_image, weak_pixels, strong_pixels)\n",
    "\n",
    "imgplot = plt.imshow(hysteresys_img, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hysteresis algorithm helped us to restore some of the necessary pixels and the lines of the image are now less intermittent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that image noise was decreased and the lines are visible much better now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Hough space algorithm\n",
    "\n",
    "accumulator, rhos, thetas = hough_lines_acc(hysteresys_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will plot the Hough space. The brighter spots correspond to more prominent lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hough_lines(sample_image, hysteresys_img, accumulator, rhos, thetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see the intersection which are the prominent lines.\n",
    "\n",
    "Main inspiration was taken from http://homepages.inf.ed.ac.uk/rbf/HIPR2/hough.htm about the logic and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two curves have a point of intersection — and this point describes the equation of the line in the image space. The 2 points independently can belong to a lot of possible lines (as they p and θ can vary). However, there is only one possible (p, θ) line, which goes through both of the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hough_acc_peaks = hough_peaks(accumulator, 3)\n",
    "lines_list = hough_lines_transofrm(hough_acc_peaks, rhos, thetas, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines_list:\n",
    "    print(line[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2image = cv2.imread(sample_image_name, 0)\n",
    "\n",
    "plot_lines(cv2image, lines_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
